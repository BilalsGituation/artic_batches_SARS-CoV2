#!/bin/bash


# Max number of parallel jobs
max_jobs=$(nproc --all)   

counter=0
total_files=$(find artic_results -wholename "*/*.pass.vcf" | wc -l)

# Clear out the merged summary file
rm -fv artic_results/merged_snpEff_genes.txt

for vcf_file in artic_results/*/*.pass.vcf
do
    ((counter++))
    accession=$(basename "$vcf_file" .pass.vcf)
    echo "                         "
    echo "================================="
    echo "[$counter/$total_files] Processing: $accession"
    echo "Input file: $vcf_file"
    echo "================================="
    rm -fv "${vcf_file%.vcf}.snpeff.vcf"
    # Appending & to a bash command gets it to run in the background (for parallel runs)
    # Wrapping 2+ commands in ( ) creates a subshell which runs them then closes (for parallel runs)  
    (
        # Run snpeff on the accession.pass.vcf file
        snpEff -csvStats "${vcf_file%.pass.vcf}_snpEff_out.csv" \
               -stats "${vcf_file%.pass.vcf}_snpEff_summary.html" \
                MN908947.3 \
                "$vcf_file" > "${vcf_file%.vcf}.snpeff.vcf" 

        # append summary .txt to merged with accession and formatted timestamps
        timedatectl | sed -n '1p' | xargs | tr -d '\t'  >> artic_results/merged_snpEff_genes.txt
        echo "[$accession]" >> artic_results/merged_snpEff_genes.txt
        cat artic_results/$accession/${accession}_snpEff_summary.genes.txt >> artic_results/merged_snpEff_genes.txt
        echo " " >> artic_results/merged_snpEff_genes.txt

        
        echo "Finished $accession"
        ) &

    # Wait if the number of running jobs reaches your CPU's maximum
    # Explanation: "jobs -r" lists currently running background jobs. wc -l counts them. -ge is greater than or equal to.
    while [[ $(jobs -r | wc -l) -ge $max_jobs ]]; do
        sleep 1
    done

done

# wait for any remaining jobs to finish
wait

echo "All $total_files samples processed!"

multiqc artic_results --force